{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0495a60c-186e-4300-b187-e30f4ca093cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-28T12:24:56.359428Z",
     "iopub.status.busy": "2024-09-28T12:24:56.358377Z",
     "iopub.status.idle": "2024-09-28T12:25:17.655080Z",
     "shell.execute_reply": "2024-09-28T12:25:17.654134Z",
     "shell.execute_reply.started": "2024-09-28T12:24:56.359390Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.45.1-py3-none-any.whl.metadata (44 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
      "Collecting huggingface-hub<1.0,>=0.23.2 (from transformers)\n",
      "  Downloading huggingface_hub-0.25.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/jupyter/.local/lib/python3.10/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.4.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting tokenizers<0.21,>=0.20 (from transformers)\n",
      "  Downloading tokenizers-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2023.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.7.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
      "Downloading transformers-4.45.1-py3-none-any.whl (9.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.25.1-py3-none-any.whl (436 kB)\n",
      "Downloading safetensors-0.4.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (435 kB)\n",
      "Downloading tokenizers-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m44.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: safetensors, huggingface-hub, tokenizers, transformers\n",
      "\u001b[33m  WARNING: The script huggingface-cli is installed in '/home/jupyter/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script transformers-cli is installed in '/home/jupyter/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed huggingface-hub-0.25.1 safetensors-0.4.5 tokenizers-0.20.0 transformers-4.45.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f4cdb82-6d14-4c7e-aeae-a664f42ca892",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T05:47:46.572042Z",
     "iopub.status.busy": "2024-09-29T05:47:46.570946Z",
     "iopub.status.idle": "2024-09-29T05:47:48.801242Z",
     "shell.execute_reply": "2024-09-29T05:47:48.800087Z",
     "shell.execute_reply.started": "2024-09-29T05:47:46.571983Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "155bb3ec-118b-465c-bd67-b74b0da26921",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T05:47:48.804418Z",
     "iopub.status.busy": "2024-09-29T05:47:48.803078Z",
     "iopub.status.idle": "2024-09-29T05:48:03.959437Z",
     "shell.execute_reply": "2024-09-29T05:48:03.958544Z",
     "shell.execute_reply.started": "2024-09-29T05:47:48.804371Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "path = '/home/jupyter/datasphere/project/data' # Ваш путь до директории с данными /path/to/data/\n",
    "data = pd.read_csv(os.path.join(path, 'train_events.csv'))\n",
    "video = pd.read_csv(os.path.join(path, 'video_info_v2.csv'))\n",
    "targets = pd.read_csv(os.path.join(path, 'train_targets.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f39de21c-f55b-4744-b7cd-605a94d8e5bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T05:48:03.961757Z",
     "iopub.status.busy": "2024-09-29T05:48:03.960851Z",
     "iopub.status.idle": "2024-09-29T05:48:04.005773Z",
     "shell.execute_reply": "2024-09-29T05:48:04.004857Z",
     "shell.execute_reply.started": "2024-09-29T05:48:03.961713Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69315362-8c07-490d-b7fe-c97a4cc018fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T05:48:04.008421Z",
     "iopub.status.busy": "2024-09-29T05:48:04.006857Z",
     "iopub.status.idle": "2024-09-29T05:48:04.024603Z",
     "shell.execute_reply": "2024-09-29T05:48:04.023720Z",
     "shell.execute_reply.started": "2024-09-29T05:48:04.008372Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device='cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee5c4983-46e6-4579-b4db-0f7f59030fc6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T05:48:05.458455Z",
     "iopub.status.busy": "2024-09-29T05:48:05.457318Z",
     "iopub.status.idle": "2024-09-29T05:48:15.321424Z",
     "shell.execute_reply": "2024-09-29T05:48:15.320328Z",
     "shell.execute_reply.started": "2024-09-29T05:48:05.458405Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.10/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModel, T5EncoderModel\n",
    "import torch\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "def generate_embeddings(df, model, tokenizer) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Функция для генерации эмбеддингов для текстов из колонки датафрейма с использованием модели из Hugging Face.\n",
    "\n",
    "    :param df: Датафрейм с колонками 'rutube_video_id' и 'title'.\n",
    "    :param model: Модель для генерации эмбеддингов.\n",
    "    :param tokenizer: Токенайзер для модели.\n",
    "    :return: Датафрейм с добавленными колонками для эмбеддингов.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Функция для получения эмбеддингов текста\n",
    "    def get_embedding(text):\n",
    "        inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True)\n",
    "        inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        # Усредняем эмбеддинг по всем токенам (mean pooling)\n",
    "        embedding = outputs.last_hidden_state.mean(dim=1).squeeze().cpu().numpy()\n",
    "        return embedding\n",
    "\n",
    "    # Получаем эмбеддинги\n",
    "    embeddings = df['title'].progress_apply(get_embedding)\n",
    "\n",
    "    # Преобразуем список эмбеддингов в отдельные колонки датафрейма\n",
    "    embeddings_df = pd.DataFrame(embeddings.tolist(), index=df.index)  # Устанавливаем индексы такие же, как у исходного датафрейма\n",
    "\n",
    "    # Назначаем имена колонкам, например 'embedding_0', 'embedding_1', и т.д.\n",
    "    embeddings_df.columns = [f'embedding_{i}' for i in range(embeddings_df.shape[1])]\n",
    "\n",
    "    # Объединяем исходный датафрейм с эмбеддингами\n",
    "    df_final = pd.concat([df, embeddings_df], axis=1)\n",
    "\n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5add9374-86c1-4a9c-b569-d450da0af214",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T05:58:46.866214Z",
     "iopub.status.busy": "2024-09-29T05:58:46.864764Z",
     "iopub.status.idle": "2024-09-29T05:58:53.747703Z",
     "shell.execute_reply": "2024-09-29T05:58:53.746645Z",
     "shell.execute_reply.started": "2024-09-29T05:58:46.866162Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(83828, 312, padding_idx=0)\n",
       "    (position_embeddings): Embedding(2048, 312)\n",
       "    (token_type_embeddings): Embedding(2, 312)\n",
       "    (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-2): 3 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=312, out_features=312, bias=True)\n",
       "            (key): Linear(in_features=312, out_features=312, bias=True)\n",
       "            (value): Linear(in_features=312, out_features=312, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=312, out_features=312, bias=True)\n",
       "            (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=312, out_features=600, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=600, out_features=312, bias=True)\n",
       "          (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=312, out_features=312, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Генерируем эмбеддинги с помощью модели 'DeepPavlov/rubert-base-cased'\n",
    "model_name = 'cointegrated/rubert-tiny2'\n",
    "\n",
    "# Загружаем модель и токенизатор\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "659b5ff0-b9c3-4ca4-a2c9-10fcb26efd61",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T04:34:59.221898Z",
     "iopub.status.busy": "2024-09-29T04:34:59.221128Z",
     "iopub.status.idle": "2024-09-29T04:35:00.194958Z",
     "shell.execute_reply": "2024-09-29T04:35:00.194144Z",
     "shell.execute_reply.started": "2024-09-29T04:34:59.221864Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1759616 entries, 0 to 1759615\n",
      "Data columns (total 13 columns):\n",
      " #   Column           Dtype \n",
      "---  ------           ----- \n",
      " 0   event_timestamp  object\n",
      " 1   region           object\n",
      " 2   ua_device_type   object\n",
      " 3   ua_client_type   object\n",
      " 4   ua_os            object\n",
      " 5   ua_client_name   object\n",
      " 6   total_watchtime  int64 \n",
      " 7   rutube_video_id  object\n",
      " 8   viewer_uid       int64 \n",
      " 9   title            object\n",
      " 10  category         object\n",
      " 11  duration         int64 \n",
      " 12  author_id        int64 \n",
      "dtypes: int64(4), object(9)\n",
      "memory usage: 187.9+ MB\n"
     ]
    }
   ],
   "source": [
    "full_df = data.merge(video, on='rutube_video_id')\n",
    "full_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2083398d-466e-4997-8166-e512a0a73654",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_embeddings = generate_embeddings(video, model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f51c7780-9805-4bd4-9e12-ff15ceac12a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-29T06:06:39.132284Z",
     "iopub.status.busy": "2024-09-29T06:06:39.131297Z",
     "iopub.status.idle": "2024-09-29T06:07:10.218717Z",
     "shell.execute_reply": "2024-09-29T06:07:10.217834Z",
     "shell.execute_reply.started": "2024-09-29T06:06:39.132242Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_with_embeddings.to_csv('/home/jupyter/datasphere/project/video_embed.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataSphere Kernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
